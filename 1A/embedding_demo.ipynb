{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Real Embeddings Demo\n",
        "\n",
        "This notebook demonstrates **actual embeddings** using `sentence-transformers` with the `all-MiniLM-L6-v2` model.\n",
        "\n",
        "**Model Details:**\n",
        "- Size: ~80MB (downloads on first run)\n",
        "- Dimensions: 384\n",
        "- Speed: Fast, works on CPU\n",
        "\n",
        "**What we'll explore:**\n",
        "1. Basic semantic similarity\n",
        "2. Sentence embeddings vs word embeddings\n",
        "3. Embedding failure modes (negation blindness, entity confusion)\n",
        "4. Simple semantic search\n",
        "\n",
        "**Prerequisites:**\n",
        "```bash\n",
        "pip install sentence-transformers\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading all-MiniLM-L6-v2...\n",
            "Model loaded! Embedding dimension: 384\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================================\n",
        "# STEP 1: Load the embedding model\n",
        "# ==========================================================================\n",
        "# sentence-transformers wraps HuggingFace models for easy sentence embedding.\n",
        "# all-MiniLM-L6-v2 is a popular choice: small, fast, and good quality.\n",
        "#\n",
        "# First run downloads the model (~80MB). Subsequent runs use cached version.\n",
        "# ==========================================================================\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "print(\"Loading all-MiniLM-L6-v2...\")\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(f\"Model loaded! Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: 'The quick brown fox jumps over the lazy dog.'\n",
            "\n",
            "Embedding shape: (384,)\n",
            "\n",
            "First 10 dimensions: [ 0.0439  0.0589  0.0482  0.0775  0.0267 -0.0376 -0.0026 -0.0599 -0.0025\n",
            "  0.0221]\n",
            "\n",
            "Embedding range: [-0.1330, 0.1768]\n",
            "Embedding norm: 1.0000\n",
            "\n",
            "(Embeddings are normalized, so norm ≈ 1.0)\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================================\n",
        "# STEP 2: Basic embedding generation\n",
        "# ==========================================================================\n",
        "# Let's see what an embedding actually looks like.\n",
        "# It's just a list of 384 floating point numbers!\n",
        "# ==========================================================================\n",
        "\n",
        "text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "embedding = model.encode(text)\n",
        "\n",
        "print(f\"Text: '{text}'\")\n",
        "print(f\"\\nEmbedding shape: {embedding.shape}\")\n",
        "print(f\"\\nFirst 10 dimensions: {embedding[:10].round(4)}\")\n",
        "print(f\"\\nEmbedding range: [{embedding.min():.4f}, {embedding.max():.4f}]\")\n",
        "print(f\"Embedding norm: {np.linalg.norm(embedding):.4f}\")\n",
        "print(\"\\n(Embeddings are normalized, so norm ≈ 1.0)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Semantic Similarity Matrix\n",
            "======================================================================\n",
            "\n",
            "Sentences:\n",
            "  [0] I love programming in Python.\n",
            "  [1] Python is my favorite programming language.\n",
            "  [2] I enjoy coding with Python.\n",
            "  [3] The weather is nice today.\n",
            "  [4] It's a beautiful sunny day.\n",
            "  [5] My cat is sleeping on the couch.\n",
            "\n",
            "Similarity scores (1.0 = identical meaning, 0.0 = unrelated):\n",
            "----------------------------------------------------------------------\n",
            "  [0] vs [0]: 1.000 ████████████████████████████████████████\n",
            "  [0] vs [1]: 0.878 ███████████████████████████████████\n",
            "  [0] vs [2]: 0.931 █████████████████████████████████████\n",
            "  [0] vs [3]: 0.063 ██\n",
            "  [0] vs [4]: 0.138 █████\n",
            "  [0] vs [5]: 0.095 ███\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Notice: [0], [1], [2] are semantically similar (all about Python coding).\n",
            "[3], [4] are about weather. [5] is about cats — unrelated to [0].\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================================\n",
        "# STEP 3: Semantic similarity — the core use case\n",
        "# ==========================================================================\n",
        "# Embeddings capture MEANING. Similar meanings → similar vectors.\n",
        "# We measure similarity using cosine similarity (dot product for unit vectors).\n",
        "#\n",
        "# This is the foundation of:\n",
        "#   - Semantic search (find similar documents)\n",
        "#   - RAG (retrieve relevant context)\n",
        "#   - Clustering (group similar items)\n",
        "# ==========================================================================\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    \"\"\"Cosine similarity between two vectors.\"\"\"\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "# Test sentences\n",
        "sentences = [\n",
        "    \"I love programming in Python.\",\n",
        "    \"Python is my favorite programming language.\",\n",
        "    \"I enjoy coding with Python.\",\n",
        "    \"The weather is nice today.\",\n",
        "    \"It's a beautiful sunny day.\",\n",
        "    \"My cat is sleeping on the couch.\",\n",
        "]\n",
        "\n",
        "# Encode all sentences at once (batched for efficiency)\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "print(\"Semantic Similarity Matrix\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nSentences:\")\n",
        "for i, s in enumerate(sentences):\n",
        "    print(f\"  [{i}] {s}\")\n",
        "\n",
        "print(\"\\nSimilarity scores (1.0 = identical meaning, 0.0 = unrelated):\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Compare first sentence to all others\n",
        "base = embeddings[0]\n",
        "for i, (sent, emb) in enumerate(zip(sentences, embeddings)):\n",
        "    sim = cosine_similarity(base, emb)\n",
        "    bar = \"█\" * int(sim * 40)\n",
        "    print(f\"  [0] vs [{i}]: {sim:.3f} {bar}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 70)\n",
        "print(\"Notice: [0], [1], [2] are semantically similar (all about Python coding).\")\n",
        "print(\"[3], [4] are about weather. [5] is about cats — unrelated to [0].\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word Embedding Similarities\n",
            "======================================================================\n",
            "  king       ↔ queen     : 0.681 ███████████████████████████\n",
            "  king       ↔ man       : 0.322 ████████████\n",
            "  queen      ↔ woman     : 0.439 █████████████████\n",
            "  prince     ↔ princess  : 0.681 ███████████████████████████\n",
            "  king       ↔ prince    : 0.588 ███████████████████████\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Vector arithmetic: king - man + woman = ?\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Finding closest word to (king - man + woman):\n",
            "  king      : 0.631 █████████████████████████\n",
            "  queen     : 0.579 ███████████████████████ ← closest!\n",
            "  man       : -0.236 \n",
            "  woman     : 0.628 █████████████████████████\n",
            "  prince    : 0.388 ███████████████\n",
            "  princess  : 0.442 █████████████████\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Result: Closest match is 'queen' with similarity 0.579\n",
            "SUCCESS: The analogy worked!\n",
            "\n",
            "NOTE: Sentence embeddings don't preserve word-level arithmetic.\n",
            "For classic king-man+woman=queen, use Word2Vec or GloVe.\n",
            "Sentence embeddings excel at comparing SENTENCES, not single words.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================================\n",
        "# STEP 4: Sentence embeddings vs word embeddings\n",
        "# ==========================================================================\n",
        "# The famous \"king - man + woman = queen\" works with WORD embeddings\n",
        "# (like Word2Vec), not sentence embeddings.\n",
        "#\n",
        "# Sentence embeddings capture the meaning of the WHOLE sentence.\n",
        "# Single words get embedded, but the arithmetic doesn't work the same way.\n",
        "#\n",
        "# Let's see what happens:\n",
        "# ==========================================================================\n",
        "\n",
        "words = [\"king\", \"queen\", \"man\", \"woman\", \"prince\", \"princess\"]\n",
        "word_embeddings = {w: model.encode(w) for w in words}\n",
        "\n",
        "print(\"Word Embedding Similarities\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "pairs = [\n",
        "    (\"king\", \"queen\"),\n",
        "    (\"king\", \"man\"),\n",
        "    (\"queen\", \"woman\"),\n",
        "    (\"prince\", \"princess\"),\n",
        "    (\"king\", \"prince\"),\n",
        "]\n",
        "\n",
        "for w1, w2 in pairs:\n",
        "    sim = cosine_similarity(word_embeddings[w1], word_embeddings[w2])\n",
        "    bar = \"█\" * int(sim * 40)\n",
        "    print(f\"  {w1:10} ↔ {w2:10}: {sim:.3f} {bar}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 70)\n",
        "print(\"Vector arithmetic: king - man + woman = ?\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "result = word_embeddings[\"king\"] - word_embeddings[\"man\"] + word_embeddings[\"woman\"]\n",
        "\n",
        "# Find the actual closest word (excluding input words)\n",
        "best_word = None\n",
        "best_sim = -1\n",
        "for word, emb in word_embeddings.items():\n",
        "    if word not in [\"king\", \"man\", \"woman\"]:\n",
        "        sim = cosine_similarity(result, emb)\n",
        "        if sim > best_sim:\n",
        "            best_sim = sim\n",
        "            best_word = word\n",
        "\n",
        "print(\"\\nFinding closest word to (king - man + woman):\")\n",
        "for word, emb in word_embeddings.items():\n",
        "    sim = cosine_similarity(result, emb)\n",
        "    bar = \"█\" * int(sim * 40) if sim > 0 else \"\"\n",
        "    marker = \" ← closest!\" if word == best_word else \"\"\n",
        "    print(f\"  {word:10}: {sim:.3f} {bar}{marker}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 70)\n",
        "print(f\"Result: Closest match is '{best_word}' with similarity {best_sim:.3f}\")\n",
        "if best_word == \"queen\":\n",
        "    print(\"SUCCESS: The analogy worked!\")\n",
        "else:\n",
        "    print(\"The analogy didn't perfectly work — this is EXPECTED.\")\n",
        "print()\n",
        "print(\"NOTE: Sentence embeddings don't preserve word-level arithmetic.\")\n",
        "print(\"For classic king-man+woman=queen, use Word2Vec or GloVe.\")\n",
        "print(\"Sentence embeddings excel at comparing SENTENCES, not single words.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Negation Blindness Demo\n",
            "======================================================================\n",
            "\n",
            "PROBLEM: Embeddings often treat 'X' and 'not X' as similar!\n",
            "This is dangerous for retrieval — you might get opposite meaning.\n",
            "\n",
            "Similarity between sentences and their NEGATIONS:\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "  'The system is secure.'\n",
            "  'The system is not secure.'\n",
            "  Similarity: 0.829 █████████████████████████████████ ⚠️ HIGH!\n",
            "\n",
            "  'I love this movie.'\n",
            "  'I hate this movie.'\n",
            "  Similarity: 0.721 ████████████████████████████ ⚠️ HIGH!\n",
            "\n",
            "  'The product works well.'\n",
            "  'The product does not work.'\n",
            "  Similarity: 0.642 █████████████████████████ \n",
            "\n",
            "  'This is allowed.'\n",
            "  'This is not allowed.'\n",
            "  Similarity: 0.875 ██████████████████████████████████ ⚠️ HIGH!\n",
            "\n",
            "  'Payment was successful.'\n",
            "  'Payment failed.'\n",
            "  Similarity: 0.660 ██████████████████████████ \n",
            "\n",
            "----------------------------------------------------------------------\n",
            "TAKEAWAY: Don't rely on embeddings alone for negation-sensitive queries.\n",
            "Consider hybrid search (embedding + keyword) or reranking.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================================\n",
        "# STEP 5: FAILURE MODE — Negation Blindness\n",
        "# ==========================================================================\n",
        "# This is a CRITICAL limitation for RAG systems!\n",
        "#\n",
        "# Embeddings are trained via contrastive learning: they learn that\n",
        "# \"X is secure\" and \"X is not secure\" appear in similar contexts.\n",
        "#\n",
        "# Result: Negation is often IGNORED in similarity calculations.\n",
        "# ==========================================================================\n",
        "\n",
        "print(\"Negation Blindness Demo\")\n",
        "print(\"=\" * 70)\n",
        "print()\n",
        "print(\"PROBLEM: Embeddings often treat 'X' and 'not X' as similar!\")\n",
        "print(\"This is dangerous for retrieval — you might get opposite meaning.\")\n",
        "print()\n",
        "\n",
        "negation_pairs = [\n",
        "    (\"The system is secure.\", \"The system is not secure.\"),\n",
        "    (\"I love this movie.\", \"I hate this movie.\"),\n",
        "    (\"The product works well.\", \"The product does not work.\"),\n",
        "    (\"This is allowed.\", \"This is not allowed.\"),\n",
        "    (\"Payment was successful.\", \"Payment failed.\"),\n",
        "]\n",
        "\n",
        "print(\"Similarity between sentences and their NEGATIONS:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for pos, neg in negation_pairs:\n",
        "    emb_pos = model.encode(pos)\n",
        "    emb_neg = model.encode(neg)\n",
        "    sim = cosine_similarity(emb_pos, emb_neg)\n",
        "    \n",
        "    # Color code: high similarity for opposites = BAD\n",
        "    warning = \"⚠️ HIGH!\" if sim > 0.7 else \"  (good)\" if sim < 0.5 else \"\"\n",
        "    bar = \"█\" * int(sim * 40)\n",
        "    \n",
        "    print(f\"\\n  '{pos}'\")\n",
        "    print(f\"  '{neg}'\")\n",
        "    print(f\"  Similarity: {sim:.3f} {bar} {warning}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 70)\n",
        "print(\"TAKEAWAY: Don't rely on embeddings alone for negation-sensitive queries.\")\n",
        "print(\"Consider hybrid search (embedding + keyword) or reranking.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entity Confusion Demo\n",
            "======================================================================\n",
            "\n",
            "PROBLEM: Embeddings see 'database config' as similar regardless of WHICH database!\n",
            "\n",
            "Scenario: User wants PostgreSQL help but query doesn't mention it\n",
            "\n",
            "Query: 'How do I configure database connection pooling?'\n",
            "\n",
            "Document rankings by embedding similarity:\n",
            "----------------------------------------------------------------------\n",
            "  1. [0.635] █████████████████████████\n",
            "     [MySQL] MySQL connection pooling is configured in my.cnf with max_connections.\n",
            "\n",
            "  2. [0.616] ████████████████████████\n",
            "     [PostgreSQL] PostgreSQL uses pgBouncer for connection pooling configuration.\n",
            "\n",
            "  3. [0.604] ████████████████████████\n",
            "     [MongoDB] MongoDB connection pools are set in the connection string options.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "OBSERVATION: Score spread is only 0.030!\n",
            "All three databases score similarly for the same semantic concept.\n",
            "\n",
            "If the user wanted PostgreSQL specifically, they might get MySQL docs!\n",
            "The embedding doesn't know WHICH database the user cares about.\n",
            "\n",
            "TAKEAWAY: For entity-specific queries, combine embeddings with:\n",
            "  - Metadata filtering (filter by database='PostgreSQL' FIRST)\n",
            "  - Keyword matching (BM25 boosts 'PostgreSQL' keyword)\n",
            "  - Query expansion (explicitly add entity name to query)\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================================\n",
        "# STEP 6: FAILURE MODE — Entity Confusion\n",
        "# ==========================================================================\n",
        "# Embeddings capture semantic SIMILARITY, not identity.\n",
        "# Similar entities (e.g., PostgreSQL vs MySQL) look similar in embedding space.\n",
        "#\n",
        "# This can be a problem when you need to distinguish between specific entities.\n",
        "# ==========================================================================\n",
        "\n",
        "print(\"Entity Confusion Demo\")\n",
        "print(\"=\" * 70)\n",
        "print()\n",
        "print(\"PROBLEM: Embeddings see 'database config' as similar regardless of WHICH database!\")\n",
        "print()\n",
        "\n",
        "# Real-world scenario: Generic query that doesn't mention the entity\n",
        "# This is where confusion happens - user knows what they want but query is vague\n",
        "print(\"Scenario: User wants PostgreSQL help but query doesn't mention it\")\n",
        "print()\n",
        "\n",
        "query = \"How do I configure database connection pooling?\"  # No entity name!\n",
        "docs = [\n",
        "    (\"PostgreSQL uses pgBouncer for connection pooling configuration.\", \"PostgreSQL\"),\n",
        "    (\"MySQL connection pooling is configured in my.cnf with max_connections.\", \"MySQL\"),\n",
        "    (\"MongoDB connection pools are set in the connection string options.\", \"MongoDB\"),\n",
        "]\n",
        "\n",
        "query_emb = model.encode(query)\n",
        "\n",
        "print(f\"Query: '{query}'\")\n",
        "print()\n",
        "print(\"Document rankings by embedding similarity:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "results = []\n",
        "for doc_text, db_name in docs:\n",
        "    doc_emb = model.encode(doc_text)\n",
        "    sim = cosine_similarity(query_emb, doc_emb)\n",
        "    results.append((sim, doc_text, db_name))\n",
        "\n",
        "# Sort by similarity\n",
        "results.sort(reverse=True)\n",
        "\n",
        "for i, (sim, doc_text, db_name) in enumerate(results, 1):\n",
        "    bar = \"█\" * int(sim * 40)\n",
        "    print(f\"  {i}. [{sim:.3f}] {bar}\")\n",
        "    print(f\"     [{db_name}] {doc_text}\")\n",
        "    print()\n",
        "\n",
        "# Calculate how close the scores are\n",
        "scores = [r[0] for r in results]\n",
        "score_spread = scores[0] - scores[-1]\n",
        "\n",
        "print(\"-\" * 70)\n",
        "print(f\"OBSERVATION: Score spread is only {score_spread:.3f}!\")\n",
        "print(\"All three databases score similarly for the same semantic concept.\")\n",
        "print()\n",
        "print(\"If the user wanted PostgreSQL specifically, they might get MySQL docs!\")\n",
        "print(\"The embedding doesn't know WHICH database the user cares about.\")\n",
        "print()\n",
        "print(\"TAKEAWAY: For entity-specific queries, combine embeddings with:\")\n",
        "print(\"  - Metadata filtering (filter by database='PostgreSQL' FIRST)\")\n",
        "print(\"  - Keyword matching (BM25 boosts 'PostgreSQL' keyword)\")\n",
        "print(\"  - Query expansion (explicitly add entity name to query)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Semantic Search Demo\n",
            "======================================================================\n",
            "\n",
            "Query: 'How do I write SQL to fetch data?'\n",
            "------------------------------------------------------------\n",
            "  1. [0.675] SQL queries retrieve data from relational databases.\n",
            "  2. [0.248] PostgreSQL is a powerful open-source relational database system.\n",
            "  3. [0.111] REST APIs use HTTP methods like GET, POST, PUT, DELETE.\n",
            "\n",
            "Query: 'What tools are used for deep learning?'\n",
            "------------------------------------------------------------\n",
            "  1. [0.657] TensorFlow and PyTorch are popular deep learning frameworks.\n",
            "  2. [0.363] Machine learning models require large datasets for training.\n",
            "  3. [0.248] Neural networks are inspired by biological brain structure.\n",
            "\n",
            "Query: 'How to manage code versions?'\n",
            "------------------------------------------------------------\n",
            "  1. [0.538] Git is a distributed version control system for tracking code changes.\n",
            "  2. [0.138] Docker containers package applications with their dependencies.\n",
            "  3. [0.101] Python is a high-level programming language known for its readability.\n",
            "\n",
            "======================================================================\n",
            "This is the core of RAG retrieval!\n",
            "In production, use a vector database (Pinecone, Weaviate, pgvector).\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================================\n",
        "# STEP 7: Simple Semantic Search\n",
        "# ==========================================================================\n",
        "# This is the foundation of RAG retrieval.\n",
        "# Given a query, find the most similar documents.\n",
        "# ==========================================================================\n",
        "\n",
        "print(\"Semantic Search Demo\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Simulated document corpus (in real RAG, these are your chunks)\n",
        "documents = [\n",
        "    \"Python is a high-level programming language known for its readability.\",\n",
        "    \"Machine learning models require large datasets for training.\",\n",
        "    \"PostgreSQL is a powerful open-source relational database system.\",\n",
        "    \"REST APIs use HTTP methods like GET, POST, PUT, DELETE.\",\n",
        "    \"Docker containers package applications with their dependencies.\",\n",
        "    \"Git is a distributed version control system for tracking code changes.\",\n",
        "    \"Neural networks are inspired by biological brain structure.\",\n",
        "    \"Kubernetes orchestrates containerized applications at scale.\",\n",
        "    \"SQL queries retrieve data from relational databases.\",\n",
        "    \"TensorFlow and PyTorch are popular deep learning frameworks.\",\n",
        "]\n",
        "\n",
        "# Pre-compute document embeddings (do this once, store in vector DB)\n",
        "doc_embeddings = model.encode(documents)\n",
        "\n",
        "def semantic_search(query, top_k=3):\n",
        "    \"\"\"Find top_k most similar documents to query.\"\"\"\n",
        "    query_emb = model.encode(query)\n",
        "    \n",
        "    # Compute similarities\n",
        "    similarities = [cosine_similarity(query_emb, doc_emb) for doc_emb in doc_embeddings]\n",
        "    \n",
        "    # Sort by similarity (descending)\n",
        "    ranked = sorted(enumerate(similarities), key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    return [(documents[i], sim) for i, sim in ranked[:top_k]]\n",
        "\n",
        "# Test queries\n",
        "queries = [\n",
        "    \"How do I write SQL to fetch data?\",\n",
        "    \"What tools are used for deep learning?\",\n",
        "    \"How to manage code versions?\",\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    print(f\"\\nQuery: '{query}'\")\n",
        "    print(\"-\" * 60)\n",
        "    results = semantic_search(query)\n",
        "    for i, (doc, sim) in enumerate(results, 1):\n",
        "        print(f\"  {i}. [{sim:.3f}] {doc}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"This is the core of RAG retrieval!\")\n",
        "print(\"In production, use a vector database (Pinecone, Weaviate, pgvector).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Why Hybrid Search?\n",
            "======================================================================\n",
            "\n",
            "Query: 'PostgreSQL indexing'\n",
            "\n",
            "Pure Embedding Search (semantic only):\n",
            "------------------------------------------------------------\n",
            "  [0.667] PostgreSQL supports advanced indexing with GIN and GiST.\n",
            "  [0.137] MySQL uses InnoDB as its default storage engine.\n",
            "  [0.603] Database indexing improves query performance significantly.\n",
            "\n",
            "------------------------------------------------------------\n",
            "PROBLEM: MySQL doc might rank close to PostgreSQL doc!\n",
            "\n",
            "With hybrid search, we'd also check for 'PostgreSQL' keyword.\n",
            "Keyword match would boost the PostgreSQL doc's rank.\n",
            "\n",
            "Hybrid = Semantic similarity + Keyword relevance (e.g., BM25)\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================================\n",
        "# STEP 8: Why Hybrid Search?\n",
        "# ==========================================================================\n",
        "# Pure embedding search has limitations (negation, entities).\n",
        "# Hybrid search combines embeddings with keyword matching.\n",
        "#\n",
        "# This demo shows WHY you might want hybrid search.\n",
        "# ==========================================================================\n",
        "\n",
        "print(\"Why Hybrid Search?\")\n",
        "print(\"=\" * 70)\n",
        "print()\n",
        "\n",
        "# Scenario: User wants PostgreSQL, but MySQL doc is semantically similar\n",
        "corpus = [\n",
        "    \"PostgreSQL supports advanced indexing with GIN and GiST.\",\n",
        "    \"MySQL uses InnoDB as its default storage engine.\",\n",
        "    \"Database indexing improves query performance significantly.\",\n",
        "]\n",
        "\n",
        "query = \"PostgreSQL indexing\"\n",
        "query_emb = model.encode(query)\n",
        "corpus_embs = model.encode(corpus)\n",
        "\n",
        "print(f\"Query: '{query}'\")\n",
        "print(\"\\nPure Embedding Search (semantic only):\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for i, (doc, emb) in enumerate(zip(corpus, corpus_embs)):\n",
        "    sim = cosine_similarity(query_emb, emb)\n",
        "    print(f\"  [{sim:.3f}] {doc}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"PROBLEM: MySQL doc might rank close to PostgreSQL doc!\")\n",
        "print(\"\\nWith hybrid search, we'd also check for 'PostgreSQL' keyword.\")\n",
        "print(\"Keyword match would boost the PostgreSQL doc's rank.\")\n",
        "print(\"\\nHybrid = Semantic similarity + Keyword relevance (e.g., BM25)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numerical Blindness Demo\n",
            "======================================================================\n",
            "\n",
            "PROBLEM: Embeddings don't understand numbers as quantities!\n",
            "\n",
            "Pairs with VERY different meanings:\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "  'The price is €100'\n",
            "  'The price is €10,000'\n",
            "  Similarity: 0.905 ████████████████████████████████████ ⚠️ HIGH!\n",
            "\n",
            "  'Server uptime is 99.9%'\n",
            "  'Server uptime is 9.9%'\n",
            "  Similarity: 0.973 ██████████████████████████████████████ ⚠️ HIGH!\n",
            "\n",
            "  'Deadline is January 5'\n",
            "  'Deadline is January 25'\n",
            "  Similarity: 0.955 ██████████████████████████████████████ ⚠️ HIGH!\n",
            "\n",
            "  '2024 annual report'\n",
            "  '2014 annual report'\n",
            "  Similarity: 0.694 ███████████████████████████ \n",
            "\n",
            "----------------------------------------------------------------------\n",
            "WHY THIS HAPPENS:\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "To embeddings, '100' and '10,000' are just different tokens.\n",
            "There's no built-in understanding that 10,000 > 100.\n",
            "\n",
            "TAKEAWAY: Extract numbers into structured metadata for comparison.\n",
            "  → price_euros: 100 vs price_euros: 10000\n",
            "  → Use numeric filters, not embedding similarity for numbers\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================================\n",
        "# STEP 9: FAILURE MODE — Numerical Blindness\n",
        "# ==========================================================================\n",
        "# Embeddings treat numbers as tokens, not quantities.\n",
        "# \"€100\" and \"€10,000\" are just different token sequences — no math!\n",
        "# ==========================================================================\n",
        "\n",
        "print(\"Numerical Blindness Demo\")\n",
        "print(\"=\" * 70)\n",
        "print()\n",
        "print(\"PROBLEM: Embeddings don't understand numbers as quantities!\")\n",
        "print()\n",
        "\n",
        "# Pairs that should be VERY different but embeddings see as similar\n",
        "number_pairs = [\n",
        "    (\"The price is €100\", \"The price is €10,000\"),\n",
        "    (\"Server uptime is 99.9%\", \"Server uptime is 9.9%\"),\n",
        "    (\"Deadline is January 5\", \"Deadline is January 25\"),\n",
        "    (\"2024 annual report\", \"2014 annual report\"),\n",
        "]\n",
        "\n",
        "print(\"Pairs with VERY different meanings:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for text1, text2 in number_pairs:\n",
        "    emb1 = model.encode(text1)\n",
        "    emb2 = model.encode(text2)\n",
        "    sim = cosine_similarity(emb1, emb2)\n",
        "    \n",
        "    bar = \"█\" * int(sim * 40)\n",
        "    warning = \"⚠️ HIGH!\" if sim > 0.8 else \"\"\n",
        "    \n",
        "    print(f\"\\n  '{text1}'\")\n",
        "    print(f\"  '{text2}'\")\n",
        "    print(f\"  Similarity: {sim:.3f} {bar} {warning}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 70)\n",
        "print(\"WHY THIS HAPPENS:\")\n",
        "print(\"-\" * 70)\n",
        "print()\n",
        "print(\"To embeddings, '100' and '10,000' are just different tokens.\")\n",
        "print(\"There's no built-in understanding that 10,000 > 100.\")\n",
        "print()\n",
        "print(\"TAKEAWAY: Extract numbers into structured metadata for comparison.\")\n",
        "print(\"  → price_euros: 100 vs price_euros: 10000\")\n",
        "print(\"  → Use numeric filters, not embedding similarity for numbers\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hybrid Search with ChromaDB\n",
            "======================================================================\n",
            "\n",
            "SCENARIO: Product documentation — user needs SPECIFIC product info\n",
            "PROBLEM: User context is 'Pro plan', but query doesn't mention it!\n",
            "\n",
            "Documents indexed in ChromaDB:\n",
            "  [free      ] API rate limits: 100 requests per minute. Exceedin...\n",
            "  [enterprise] API rate limits: 1000 requests per minute. Burst c...\n",
            "  [pro       ] API rate limits: 500 requests per minute. Includes...\n",
            "  [all       ] API authentication uses OAuth 2.0. Generate tokens...\n",
            "  [all       ] API versioning follows semver. Current stable vers...\n",
            "\n",
            "Query: 'What are the API rate limits?'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "METHOD 1: Pure Semantic Search (embedding only)\n",
            "----------------------------------------------------------------------\n",
            "Top 3 results (user is on PRO plan but didn't say so):\n",
            "  1. [0.763] [free      ] API rate limits: 100 requests per minute... ← WRONG (free)!\n",
            "  2. [0.727] [enterprise] API rate limits: 1000 requests per minut... ← WRONG (enterprise)!\n",
            "  3. [0.718] [pro       ] API rate limits: 500 requests per minute... ✓ CORRECT!\n",
            "\n",
            "PROBLEM: User gets FREE or ENTERPRISE limits, not their PRO plan!\n",
            "All 'rate limit' docs are semantically identical to embeddings.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "METHOD 2: Semantic Search + Metadata Filter\n",
            "----------------------------------------------------------------------\n",
            "Filter: product = 'pro' (from user session)\n",
            "Results:\n",
            "  1. [0.718] [pro       ] API rate limits: 500 requests per minute... ✓\n",
            "\n",
            "SUCCESS: User gets their PRO plan limits!\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "METHOD 3: Multi-Filter (topic + product)\n",
            "----------------------------------------------------------------------\n",
            "Filter: product='pro' AND topic='rate-limits'\n",
            "Results:\n",
            "  1. [0.718] [pro       ] API rate limits: 500 requests per minute... ✓\n",
            "\n",
            "PRECISE: Exact match on both product AND topic.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "KEY TAKEAWAYS:\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "1. Pure semantic search FAILS when context matters\n",
            "   → All 'rate limit' docs look identical to embeddings\n",
            "   → User gets wrong product's info (could be 10x off!)\n",
            "\n",
            "2. Metadata filtering uses CONTEXT (user plan, region, etc)\n",
            "   → User's plan is known from session — inject as filter\n",
            "   → No need for user to say 'Pro plan' in every query\n",
            "\n",
            "3. Multi-filter combines constraints\n",
            "   → product=X AND topic=Y for precise results\n",
            "\n",
            "PRODUCTION PATTERN:\n",
            "  1. Extract metadata at ingestion: product, version, region, date\n",
            "  2. Get user context from session: plan, permissions, locale\n",
            "  3. Inject context as filters BEFORE semantic search\n",
            "  4. User query stays natural: 'What are the rate limits?'\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================================\n",
        "# STEP 10: Hybrid Search with ChromaDB — Production-Ready RAG\n",
        "# ==========================================================================\n",
        "# ChromaDB is a lightweight vector database that supports:\n",
        "#   - Semantic search (embeddings)\n",
        "#   - Metadata filtering (exact matches)\n",
        "#   - Hybrid approaches combining both\n",
        "#\n",
        "# This demo shows a REAL failure mode: VERSION CONFUSION\n",
        "# Embeddings see \"Python installation\" as similar regardless of version!\n",
        "#\n",
        "# Prerequisites: pip install chromadb\n",
        "# ==========================================================================\n",
        "\n",
        "import chromadb\n",
        "\n",
        "print(\"Hybrid Search with ChromaDB\")\n",
        "print(\"=\" * 70)\n",
        "print()\n",
        "print(\"SCENARIO: Product documentation — user needs SPECIFIC product info\")\n",
        "print(\"PROBLEM: User context is 'Pro plan', but query doesn't mention it!\")\n",
        "print()\n",
        "\n",
        "# Create in-memory ChromaDB client\n",
        "client = chromadb.Client()\n",
        "\n",
        "# Create collection (uses default embedding function)\n",
        "collection = client.create_collection(\n",
        "    name=\"docs\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "# Our document corpus - REALISTIC SCENARIO\n",
        "# All docs are about \"API rate limits\" but for DIFFERENT products!\n",
        "documents = [\n",
        "    \"API rate limits: 100 requests per minute. Exceeding this will return 429 errors. Contact support for increases.\",\n",
        "    \"API rate limits: 1000 requests per minute. Burst capacity available. Enterprise SLA guarantees 99.9% uptime.\",\n",
        "    \"API rate limits: 500 requests per minute. Includes webhook support and priority queue processing.\",\n",
        "    \"API authentication uses OAuth 2.0. Generate tokens in the dashboard. Tokens expire after 24 hours.\",\n",
        "    \"API versioning follows semver. Current stable version is v3. Deprecation notices sent 6 months in advance.\",\n",
        "]\n",
        "\n",
        "# Metadata - THIS IS THE KEY!\n",
        "metadatas = [\n",
        "    {\"product\": \"free\", \"topic\": \"rate-limits\"},\n",
        "    {\"product\": \"enterprise\", \"topic\": \"rate-limits\"},\n",
        "    {\"product\": \"pro\", \"topic\": \"rate-limits\"},\n",
        "    {\"product\": \"all\", \"topic\": \"authentication\"},\n",
        "    {\"product\": \"all\", \"topic\": \"versioning\"},\n",
        "]\n",
        "\n",
        "# Add documents to collection\n",
        "collection.add(\n",
        "    documents=documents,\n",
        "    metadatas=metadatas,\n",
        "    ids=[f\"doc_{i}\" for i in range(len(documents))]\n",
        ")\n",
        "\n",
        "print(\"Documents indexed in ChromaDB:\")\n",
        "for i, (doc, meta) in enumerate(zip(documents, metadatas)):\n",
        "    print(f\"  [{meta['product']:10}] {doc[:50]}...\")\n",
        "print()\n",
        "\n",
        "# The query - user is on Pro plan but doesn't say so in query!\n",
        "query = \"What are the API rate limits?\"\n",
        "\n",
        "print(f\"Query: '{query}'\")\n",
        "print()\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# ========== METHOD 1: Pure Semantic Search ==========\n",
        "print(\"METHOD 1: Pure Semantic Search (embedding only)\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "results_semantic = collection.query(\n",
        "    query_texts=[query],\n",
        "    n_results=3\n",
        ")\n",
        "\n",
        "print(\"Top 3 results (user is on PRO plan but didn't say so):\")\n",
        "for i, (doc, distance, meta) in enumerate(zip(\n",
        "    results_semantic['documents'][0],\n",
        "    results_semantic['distances'][0],\n",
        "    results_semantic['metadatas'][0]\n",
        ")):\n",
        "    similarity = 1 - distance  # ChromaDB returns distance, not similarity\n",
        "    product = meta['product']\n",
        "    marker = \"✓ CORRECT!\" if product == \"pro\" else f\"← WRONG ({product})!\"\n",
        "    print(f\"  {i+1}. [{similarity:.3f}] [{product:10}] {doc[:40]}... {marker}\")\n",
        "\n",
        "print()\n",
        "print(\"PROBLEM: User gets FREE or ENTERPRISE limits, not their PRO plan!\")\n",
        "print(\"All 'rate limit' docs are semantically identical to embeddings.\")\n",
        "print()\n",
        "\n",
        "# ========== METHOD 2: Metadata Filtering ==========\n",
        "print(\"-\" * 70)\n",
        "print(\"METHOD 2: Semantic Search + Metadata Filter\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# In production: user's plan is known from their session/auth context\n",
        "user_plan = \"pro\"\n",
        "\n",
        "results_filtered = collection.query(\n",
        "    query_texts=[query],\n",
        "    n_results=3,\n",
        "    where={\"product\": user_plan}  # Filter by user's actual plan!\n",
        ")\n",
        "\n",
        "print(f\"Filter: product = '{user_plan}' (from user session)\")\n",
        "print(\"Results:\")\n",
        "for i, (doc, distance, meta) in enumerate(zip(\n",
        "    results_filtered['documents'][0],\n",
        "    results_filtered['distances'][0],\n",
        "    results_filtered['metadatas'][0]\n",
        ")):\n",
        "    similarity = 1 - distance\n",
        "    product = meta['product']\n",
        "    print(f\"  {i+1}. [{similarity:.3f}] [{product:10}] {doc[:40]}... ✓\")\n",
        "\n",
        "print()\n",
        "print(\"SUCCESS: User gets their PRO plan limits!\")\n",
        "print()\n",
        "\n",
        "# ========== METHOD 3: Combine topic + product filters ==========\n",
        "print(\"-\" * 70)\n",
        "print(\"METHOD 3: Multi-Filter (topic + product)\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "results_multi = collection.query(\n",
        "    query_texts=[query],\n",
        "    n_results=3,\n",
        "    where={\"$and\": [{\"product\": \"pro\"}, {\"topic\": \"rate-limits\"}]}\n",
        ")\n",
        "\n",
        "print(f\"Filter: product='pro' AND topic='rate-limits'\")\n",
        "print(\"Results:\")\n",
        "for i, (doc, distance, meta) in enumerate(zip(\n",
        "    results_multi['documents'][0],\n",
        "    results_multi['distances'][0],\n",
        "    results_multi['metadatas'][0]\n",
        ")):\n",
        "    similarity = 1 - distance\n",
        "    product = meta['product']\n",
        "    print(f\"  {i+1}. [{similarity:.3f}] [{product:10}] {doc[:40]}... ✓\")\n",
        "\n",
        "print()\n",
        "print(\"PRECISE: Exact match on both product AND topic.\")\n",
        "\n",
        "print()\n",
        "print(\"-\" * 70)\n",
        "print(\"KEY TAKEAWAYS:\")\n",
        "print(\"-\" * 70)\n",
        "print()\n",
        "print(\"1. Pure semantic search FAILS when context matters\")\n",
        "print(\"   → All 'rate limit' docs look identical to embeddings\")\n",
        "print(\"   → User gets wrong product's info (could be 10x off!)\")\n",
        "print()\n",
        "print(\"2. Metadata filtering uses CONTEXT (user plan, region, etc)\")\n",
        "print(\"   → User's plan is known from session — inject as filter\")\n",
        "print(\"   → No need for user to say 'Pro plan' in every query\")\n",
        "print()\n",
        "print(\"3. Multi-filter combines constraints\")\n",
        "print(\"   → product=X AND topic=Y for precise results\")\n",
        "print()\n",
        "print(\"PRODUCTION PATTERN:\")\n",
        "print(\"  1. Extract metadata at ingestion: product, version, region, date\")\n",
        "print(\"  2. Get user context from session: plan, permissions, locale\")\n",
        "print(\"  3. Inject context as filters BEFORE semantic search\")\n",
        "print(\"  4. User query stays natural: 'What are the rate limits?'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hierarchical Retrieval Demo\n",
            "======================================================================\n",
            "\n",
            "Indexed 5 documents\n",
            "  Summaries collection: ~43 words\n",
            "  Full docs collection: ~389 words\n",
            "\n",
            "Query: 'How do I get a refund?'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "STEP 1: Search summaries (fast, cheap)\n",
            "----------------------------------------------------------------------\n",
            "Top 2 matching summaries:\n",
            "  1. [-0.005] doc_1: Refund policy overview. 30-day money-back guarante...\n",
            "  2. [-0.394] doc_4: Payment methods. Credit cards, PayPal, and install...\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "STEP 2: Fetch full docs for top matches only\n",
            "----------------------------------------------------------------------\n",
            "Loaded 2 full documents:\n",
            "  doc_1: 125 words — 'REFUND POLICY - Complete Guide\n",
            "\n",
            "Our company offers a compreh...'\n",
            "  doc_4: 54 words — 'PAYMENT OPTIONS - Complete Guide\n",
            "\n",
            "We accept the following pa...'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "TOKEN SAVINGS ANALYSIS\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "NAIVE approach (search all full docs):\n",
            "  Index/search: 505 tokens\n",
            "\n",
            "HIERARCHICAL approach:\n",
            "  Step 1 - Search summaries: 55 tokens\n",
            "  Step 2 - Load top 2 full:  232 tokens\n",
            "  Total:                     288 tokens\n",
            "\n",
            "SAVINGS: 43% fewer tokens!\n",
            "\n",
            "At scale (10K docs, 50K queries/day):\n",
            "  Naive:        Would be impractical (full docs in every search)\n",
            "  Hierarchical: Search summaries, load only what's needed\n",
            "\n",
            "PRODUCTION PATTERN:\n",
            "  1. Pre-compute summaries at ingestion (LLM or extractive)\n",
            "  2. Index summaries in vector DB\n",
            "  3. First pass: semantic search on summaries\n",
            "  4. Second pass: fetch full docs by ID for top-k\n",
            "  5. Feed only relevant full docs to LLM\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================================\n",
        "# STEP 11: Hierarchical Retrieval — Summary-First Strategy\n",
        "# ==========================================================================\n",
        "# Instead of searching full documents directly:\n",
        "#   1. First pass: Search summaries (cheap, fast)\n",
        "#   2. Second pass: Load full docs for top matches only\n",
        "#\n",
        "# This dramatically reduces token usage in production RAG systems.\n",
        "# ==========================================================================\n",
        "\n",
        "import chromadb\n",
        "\n",
        "print(\"Hierarchical Retrieval Demo\")\n",
        "print(\"=\" * 70)\n",
        "print()\n",
        "\n",
        "# Create fresh client\n",
        "client = chromadb.Client()\n",
        "\n",
        "# Simulate a document corpus with summaries and full text\n",
        "documents = [\n",
        "    {\n",
        "        \"id\": \"doc_1\",\n",
        "        \"summary\": \"Refund policy overview. 30-day money-back guarantee for all products.\",\n",
        "        \"full_text\": \"\"\"REFUND POLICY - Complete Guide\n",
        "\n",
        "Our company offers a comprehensive 30-day money-back guarantee on all products. \n",
        "If you're not satisfied with your purchase, you can request a full refund within \n",
        "30 days of delivery. The product must be in original condition with all packaging.\n",
        "\n",
        "To request a refund:\n",
        "1. Log into your account\n",
        "2. Go to Order History\n",
        "3. Click \"Request Refund\" on the relevant order\n",
        "4. Fill out the reason for return\n",
        "5. Print the prepaid shipping label\n",
        "\n",
        "Refunds are processed within 5-7 business days after we receive the returned item.\n",
        "Original shipping costs are non-refundable unless the return is due to our error.\n",
        "\n",
        "For digital products, refunds are available within 14 days if the product hasn't \n",
        "been downloaded or accessed more than once.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc_2\", \n",
        "        \"summary\": \"Shipping information. Free shipping over $50, 3-5 business days delivery.\",\n",
        "        \"full_text\": \"\"\"SHIPPING POLICY - Detailed Information\n",
        "\n",
        "Standard Shipping: 3-5 business days, $5.99 flat rate\n",
        "Express Shipping: 1-2 business days, $15.99\n",
        "Free Shipping: Orders over $50 qualify for free standard shipping\n",
        "\n",
        "We ship to all 50 US states and select international destinations.\n",
        "International shipping rates vary by destination and package weight.\n",
        "\n",
        "Tracking information is sent via email within 24 hours of shipment.\n",
        "All orders are processed within 1 business day of payment confirmation.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc_3\",\n",
        "        \"summary\": \"Account security. Two-factor authentication and password requirements.\",\n",
        "        \"full_text\": \"\"\"ACCOUNT SECURITY - Best Practices\n",
        "\n",
        "We take your security seriously. All accounts support two-factor authentication (2FA).\n",
        "To enable 2FA, go to Settings > Security > Enable 2FA.\n",
        "\n",
        "Password requirements:\n",
        "- Minimum 12 characters\n",
        "- At least one uppercase letter\n",
        "- At least one number\n",
        "- At least one special character\n",
        "\n",
        "We recommend using a password manager and never reusing passwords across sites.\n",
        "If you suspect unauthorized access, contact support immediately.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc_4\",\n",
        "        \"summary\": \"Payment methods. Credit cards, PayPal, and installment options available.\",\n",
        "        \"full_text\": \"\"\"PAYMENT OPTIONS - Complete Guide\n",
        "\n",
        "We accept the following payment methods:\n",
        "- Visa, Mastercard, American Express, Discover\n",
        "- PayPal and PayPal Credit\n",
        "- Apple Pay and Google Pay\n",
        "- Affirm (buy now, pay later)\n",
        "\n",
        "For orders over $100, Affirm offers 0% APR financing for 3-12 months.\n",
        "All transactions are encrypted with 256-bit SSL security.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc_5\",\n",
        "        \"summary\": \"Product warranty. 1-year manufacturer warranty on all electronics.\",\n",
        "        \"full_text\": \"\"\"WARRANTY INFORMATION\n",
        "\n",
        "All electronics come with a 1-year manufacturer warranty covering defects in \n",
        "materials and workmanship. This warranty does not cover damage from misuse, \n",
        "accidents, or unauthorized modifications.\n",
        "\n",
        "To file a warranty claim:\n",
        "1. Contact customer support with your order number\n",
        "2. Describe the issue in detail\n",
        "3. Provide photos if applicable\n",
        "4. We'll arrange repair or replacement\n",
        "\n",
        "Extended warranty options are available at checkout for an additional fee.\"\"\"\n",
        "    },\n",
        "]\n",
        "\n",
        "# Create two collections: summaries and full documents\n",
        "summaries_collection = client.create_collection(name=\"summaries\")\n",
        "full_docs_collection = client.create_collection(name=\"full_docs\")\n",
        "\n",
        "# Index both\n",
        "for doc in documents:\n",
        "    summaries_collection.add(\n",
        "        documents=[doc[\"summary\"]],\n",
        "        ids=[doc[\"id\"]],\n",
        "        metadatas=[{\"doc_id\": doc[\"id\"]}]\n",
        "    )\n",
        "    full_docs_collection.add(\n",
        "        documents=[doc[\"full_text\"]],\n",
        "        ids=[doc[\"id\"]],\n",
        "        metadatas=[{\"doc_id\": doc[\"id\"]}]\n",
        "    )\n",
        "\n",
        "print(f\"Indexed {len(documents)} documents\")\n",
        "print(f\"  Summaries collection: ~{sum(len(d['summary'].split()) for d in documents)} words\")\n",
        "print(f\"  Full docs collection: ~{sum(len(d['full_text'].split()) for d in documents)} words\")\n",
        "print()\n",
        "\n",
        "# The query\n",
        "query = \"How do I get a refund?\"\n",
        "\n",
        "print(f\"Query: '{query}'\")\n",
        "print()\n",
        "print(\"-\" * 70)\n",
        "print(\"STEP 1: Search summaries (fast, cheap)\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# First pass: search summaries\n",
        "summary_results = summaries_collection.query(\n",
        "    query_texts=[query],\n",
        "    n_results=2  # Get top 2\n",
        ")\n",
        "\n",
        "print(\"Top 2 matching summaries:\")\n",
        "for i, (doc_id, summary, distance) in enumerate(zip(\n",
        "    summary_results['ids'][0],\n",
        "    summary_results['documents'][0],\n",
        "    summary_results['distances'][0]\n",
        ")):\n",
        "    sim = 1 - distance\n",
        "    print(f\"  {i+1}. [{sim:.3f}] {doc_id}: {summary[:50]}...\")\n",
        "\n",
        "# Get the IDs of relevant docs\n",
        "relevant_ids = summary_results['ids'][0]\n",
        "\n",
        "print()\n",
        "print(\"-\" * 70)\n",
        "print(\"STEP 2: Fetch full docs for top matches only\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Second pass: get full documents by ID\n",
        "full_results = full_docs_collection.get(ids=relevant_ids)\n",
        "\n",
        "print(f\"Loaded {len(relevant_ids)} full documents:\")\n",
        "for doc_id, full_text in zip(full_results['ids'], full_results['documents']):\n",
        "    word_count = len(full_text.split())\n",
        "    print(f\"  {doc_id}: {word_count} words — '{full_text[:60]}...'\")\n",
        "\n",
        "print()\n",
        "print(\"-\" * 70)\n",
        "print(\"TOKEN SAVINGS ANALYSIS\")\n",
        "print(\"-\" * 70)\n",
        "print()\n",
        "\n",
        "# Calculate savings\n",
        "total_summary_tokens = sum(len(d['summary'].split()) * 1.3 for d in documents)\n",
        "total_full_tokens = sum(len(d['full_text'].split()) * 1.3 for d in documents)\n",
        "loaded_full_tokens = sum(len(d.split()) * 1.3 for d in full_results['documents'])\n",
        "\n",
        "print(f\"NAIVE approach (search all full docs):\")\n",
        "print(f\"  Index/search: {int(total_full_tokens):,} tokens\")\n",
        "print()\n",
        "print(f\"HIERARCHICAL approach:\")\n",
        "print(f\"  Step 1 - Search summaries: {int(total_summary_tokens):,} tokens\")\n",
        "print(f\"  Step 2 - Load top 2 full:  {int(loaded_full_tokens):,} tokens\")\n",
        "print(f\"  Total:                     {int(total_summary_tokens + loaded_full_tokens):,} tokens\")\n",
        "print()\n",
        "\n",
        "savings_pct = (1 - (total_summary_tokens + loaded_full_tokens) / total_full_tokens) * 100\n",
        "print(f\"SAVINGS: {savings_pct:.0f}% fewer tokens!\")\n",
        "print()\n",
        "print(\"At scale (10K docs, 50K queries/day):\")\n",
        "naive_daily = 50000 * (total_full_tokens / len(documents)) * 10000 / 1000 * 0.003\n",
        "hier_daily = 50000 * ((total_summary_tokens + loaded_full_tokens) / len(documents)) * 100 / 1000 * 0.003\n",
        "print(f\"  Naive:        Would be impractical (full docs in every search)\")\n",
        "print(f\"  Hierarchical: Search summaries, load only what's needed\")\n",
        "print()\n",
        "print(\"PRODUCTION PATTERN:\")\n",
        "print(\"  1. Pre-compute summaries at ingestion (LLM or extractive)\")\n",
        "print(\"  2. Index summaries in vector DB\")\n",
        "print(\"  3. First pass: semantic search on summaries\")\n",
        "print(\"  4. Second pass: fetch full docs by ID for top-k\")\n",
        "print(\"  5. Feed only relevant full docs to LLM\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "**What embeddings are good at:**\n",
        "- Capturing semantic similarity (\"happy\" ≈ \"joyful\")\n",
        "- Finding related content even with different words\n",
        "- Powering semantic search and RAG retrieval\n",
        "\n",
        "**What embeddings struggle with:**\n",
        "- Negation (\"is secure\" ≈ \"is not secure\")\n",
        "- Entity disambiguation (PostgreSQL ≈ MySQL)\n",
        "- Exact matching requirements\n",
        "- Numerical reasoning\n",
        "\n",
        "**Production patterns demonstrated:**\n",
        "- **Hybrid search** (STEP 10): Semantic + metadata filtering\n",
        "- **Hierarchical retrieval** (STEP 11): Summary-first, then full docs\n",
        "\n",
        "**Practical recommendations:**\n",
        "- Use hybrid search (embeddings + metadata) for production\n",
        "- Add metadata filtering for entity-specific queries\n",
        "- Use hierarchical retrieval for large document sets\n",
        "- Consider reranking for critical applications\n",
        "- Test with your actual use cases — embedding quality varies by domain\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "jupyter-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
